{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2765a255",
   "metadata": {},
   "source": [
    "SQL - Connector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddb348f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0462a5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "connection = mysql.connector.connect(\n",
    "  host = \"gateway01.ap-southeast-1.prod.aws.tidbcloud.com\",\n",
    "  port = 4000,\n",
    "  user = \"oKkfDp6Bs76GVTg.root\",\n",
    "  password = \"jlzngSYu6mO3vwih\",\n",
    "  database = \"Stock_analysis_50\"\n",
    ")\n",
    "mycursor = connection.cursor(buffered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdf1d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database created or already exists.\n"
     ]
    }
   ],
   "source": [
    "mycursor.execute(\"CREATE DATABASE IF NOT EXISTS Stock_analysis\")\n",
    "print(\"successful\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eafd054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful\n"
     ]
    }
   ],
   "source": [
    "mycursor.execute(\"CREATE DATABASE IF NOT EXISTS Stock_analysis_50\")\n",
    "print(\"successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44c6725",
   "metadata": {},
   "source": [
    "importing a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c06bd013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully imported\n"
     ]
    }
   ],
   "source": [
    "csv_file_path = r\"C:\\prj_stock_analysis\\datas\\correlation\\correlation_matrix.csv\" \n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "columns_with_types = \", \".join([f\"`{col}` TEXT\" for col in df.columns])\n",
    "create_table_query = f\"CREATE TABLE IF NOT EXISTS Stock_analysis.Correlation_1_matrix ({columns_with_types})\"\n",
    "mycursor.execute(create_table_query)\n",
    "\n",
    "placeholders = \", \".join([\"%s\"] * len(df.columns))\n",
    "columns = \", \".join([f\"`{col}`\" for col in df.columns])\n",
    "insert_query = f\"INSERT INTO Correlation_1_matrix ({columns}) VALUES ({placeholders})\"\n",
    "\n",
    "mycursor.executemany(insert_query, df.values.tolist())\n",
    "connection.commit()\n",
    "\n",
    "print(\"successfully imported\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c491a17e",
   "metadata": {},
   "source": [
    "importing 50 csv's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6a8ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "folder_path = r\"C:\\prj_stock_analysis\\datas\\aggregated_data_1\"\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(folder_path, filename)\n",
    "        table_name = os.path.splitext(filename)[0]\n",
    "\n",
    "\n",
    "    print(f\"\\nProcessing file: {filename}\")\n",
    "    print(\"DataFrame Columns:\", df.columns)\n",
    "    print(\"DataFrame Data Types:\", df.dtypes)\n",
    "\n",
    "    columns_with_types = \", \".join([f\"`{col}` TEXT\" for col in df.columns])\n",
    "    create_table_query = f\"CREATE TABLE IF NOT EXISTS `{table_name}` ({columns_with_types})\"\n",
    "    mycursor.execute(create_table_query)\n",
    "\n",
    " \n",
    "    mycursor.execute(f\"DESCRIBE `{table_name}`\")\n",
    "    table_columns = mycursor.fetchall()\n",
    "    db_columns = [col[0] for col in table_columns]\n",
    "    print(\"Table Columns from MySQL:\", db_columns)\n",
    "\n",
    "    \n",
    "    if sorted(df.columns.tolist()) != sorted(db_columns):\n",
    "        print(f\"Warning: Columns don't match between DataFrame and MySQL table in {filename}.\")\n",
    "        print(\"DataFrame Columns:\", df.columns)\n",
    "        print(\"Table Columns:\", db_columns)\n",
    "        continue  \n",
    "\n",
    "   \n",
    "    print(\"\\nChecking for missing values in DataFrame:\")\n",
    "    print(df.isnull().sum())  \n",
    "\n",
    "    \n",
    "    df = df.dropna() \n",
    "\n",
    "    \n",
    "    placeholders = \", \".join([\"%s\"] * len(df.columns))\n",
    "    columns_str = \", \".join([f\"`{col}`\" for col in df.columns])\n",
    "    insert_query = f\"INSERT INTO `{table_name}` ({columns_str}) VALUES ({placeholders})\"\n",
    "\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        mycursor.executemany(insert_query, df.values.tolist())\n",
    "        print(f\"Successfully uploaded {filename} into table {table_name}!\")\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error inserting {filename}: {err}\")\n",
    "        connection.rollback()  \n",
    "\n",
    "\n",
    "connection.commit()\n",
    "mycursor.close()\n",
    "connection.close()\n",
    "print(\"All files processed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
