{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eee1b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7286b6fd",
   "metadata": {},
   "source": [
    "CHECKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d487c12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Ticker', 'close', 'high', 'low', 'open', 'volume', 'Day', 'Month',\n",
       "       'Year', 'Time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a1 = pd.read_csv(r\"C:\\prj_stock_analysis\\datas\\aggregated_data_1\\ADANIENT.csv\")\n",
    "a1.columns\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756854ef",
   "metadata": {},
   "source": [
    "FILE LOOP -> DAILY RETURN -> VOLATILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab03bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lOADING AND LOOPING FILE\n",
    "\n",
    "folder_path = r\"C:\\prj_stock_analysis\\datas\\aggregated_data_1\"\n",
    "for file in os.listdir(folder_path):\n",
    "    ticker = file.replace('.csv', '')  \n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path) \n",
    "\n",
    "# DAILY RETURNS FOR EACH CSV  \n",
    "        \n",
    "    df['Daily_Return'] = df['close'].pct_change()  \n",
    "        \n",
    "# VOLATILITY USING STANDARD DEVIATION\n",
    "    df['30-Day Volatility'] = df['Daily_Return'].rolling(window=30).std()\n",
    "\n",
    "       \n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Updated {ticker} with Daily Returns and Volatility\")\n",
    "    print(df.head())  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1995b2",
   "metadata": {},
   "source": [
    "# REMOVING THE EXTRA COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4970dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r\"C:\\prj_stock_analysis\\datas\\aggregated_data_1\"\n",
    "for file in os.listdir(folder_path):\n",
    "    ticker = file.replace('.csv', '')  \n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path) \n",
    "\n",
    "    if \"Daily Return\" in df.columns:\n",
    "       df = df.drop(\"Daily Return\", axis=1)\n",
    "\n",
    "    if \"Volatility\" in df.columns:\n",
    "      df = df.drop(\"Volatility\", axis=1)\n",
    "\n",
    "    #SAVING UPDATED FILE !!\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Done for {file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e877990c",
   "metadata": {},
   "source": [
    "PERCENTAGE(for ref), Mean for each stock, sort and save in new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ed53e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Ticker', 'close', 'high', 'low', 'open', 'volume', 'Day', 'Month',\n",
       "       'Year', 'Time', 'Daily_Return', '30-Day Volatility'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = pd.read_csv(r\"C:\\prj_stock_analysis\\datas\\aggregated_data_1\\ADANIENT.csv\")\n",
    "a1.columns\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4106e9",
   "metadata": {},
   "source": [
    "VOLATILITY (30 DAYS) -> AVERAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2d90cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\ADANIENT.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\ADANIPORTS.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\APOLLOHOSP.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\ASIANPAINT.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\AXISBANK.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\BAJAJ-AUTO.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\BAJAJFINSV.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\BAJFINANCE.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\BEL.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\BHARTIARTL.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\BPCL.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\BRITANNIA.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\CIPLA.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\COALINDIA.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\DRREDDY.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\EICHERMOT.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\GRASIM.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\HCLTECH.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\HDFCBANK.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\HDFCLIFE.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\HEROMOTOCO.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\HINDALCO.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\HINDUNILVR.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\ICICIBANK.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\INDUSINDBK.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\INFY.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\ITC.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\JSWSTEEL.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\KOTAKBANK.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\LT.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\M&M.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\MARUTI.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\NESTLEIND.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\NTPC.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\ONGC.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\POWERGRID.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\RELIANCE.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\SBILIFE.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\SBIN.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\SHRIRAMFIN.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\SUNPHARMA.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\TATACONSUM.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\TATAMOTORS.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\TATASTEEL.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\TCS.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\TECHM.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\TITAN.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\TRENT.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\ULTRACEMCO.csv\n",
      "Done for C:\\prj_stock_analysis\\datas\\aggregated_data_1\\WIPRO.csv\n",
      "done successfully ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "folder_path = r\"C:\\prj_stock_analysis\\datas\\aggregated_data_1\"\n",
    "\n",
    "\n",
    "stock_volatility_data = []\n",
    "\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "        ticker = file.replace('.csv', '')  \n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_csv(file_path) \n",
    "        \n",
    "        \n",
    "        df['Volatility Percentage'] = df['30-Day Volatility'] * 100 \n",
    "        df.to_csv(file_path, index=False)\n",
    "        \n",
    "    \n",
    "        avg_volatility = df['30-Day Volatility'].mean()\n",
    "        stock_volatility_data.append({'Ticker': ticker, 'Avg Volatility': avg_volatility})\n",
    "        \n",
    "        print(f\"Done for {file_path}\")\n",
    "\n",
    "volatility_df = pd.DataFrame(stock_volatility_data)\n",
    "volatility_df = volatility_df.sort_values(by='Avg Volatility', ascending=False)\n",
    "\n",
    "volatility_df.to_csv(r\"C:\\prj_stock_analysis\\datas\\volatility.csv\", index=False)\n",
    "\n",
    "print(\"done successfully\",b'\\xF0\\x9F\\x98\\x8A'.decode('utf-8'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbb900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\prj_stock_analysis\\datas\\volatility.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08189b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Volatility Percentage'] = df['Avg Volatility'] * 100 \n",
    "df.to_csv(r\"C:\\prj_stock_analysis\\datas\\volatility.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79a17a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2af06ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_volatility = df.head(10)\n",
    "final_volatility.to_csv(r\"C:\\prj_stock_analysis\\datas\\final_top_10.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58340e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top 10 volatility load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4128ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv(r\"C:\\prj_stock_analysis\\datas\\final_top_10.csv\")\n",
    "display(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a54e063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed a part ðŸ˜ŠðŸ˜ŠðŸ˜ŠðŸ˜ŠðŸ˜ŠðŸ˜ŠðŸ˜ŠðŸ˜ŠðŸ˜ŠðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "c = ''\n",
    "for i in range(10):\n",
    "    c += b'\\xF0\\x9F\\x98\\x8A'.decode('utf-8')\n",
    "print(\"Completed a part\", c)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
